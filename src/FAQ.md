# ğŸ“š PREGUNTAS FRECUENTES (FAQ)

## ğŸ¤” Preguntas Generales

### Â¿QuÃ© es Top2Vec?
Top2Vec es un algoritmo de inteligencia artificial que:
- Lee automÃ¡ticamente documentos (en este caso, noticias)
- Identifica temas recurrentes (tÃ³picos)
- Agrupa documentos similares
- No requiere que le digas cuÃ¡ntos tÃ³picos buscar (los descubre solo)

### Â¿Por quÃ© usar embeddings precalculados?
Los embeddings son representaciones numÃ©ricas de cada noticia. Calcularlos desde cero:
- â±ï¸ TomarÃ­a **varias horas** o dÃ­as
- ğŸ’¾ Requiere **mucha memoria RAM** (32GB+)
- ğŸ”¥ Necesita una **GPU potente** (opcional pero muy recomendado)

Al tenerlos precalculados, el anÃ¡lisis completo toma solo **15-30 minutos**.

### Â¿QuÃ© tan bueno es el modelo?
La calidad depende de:
- âœ… Cantidad de datos (mÃ¡s datos = mejores tÃ³picos)
- âœ… Calidad del preprocesamiento de texto
- âœ… ConfiguraciÃ³n de parÃ¡metros adecuada

Con 100,000+ noticias econÃ³micas, los resultados son muy buenos.

---

## âš™ï¸ Preguntas sobre ParÃ¡metros

### Â¿QuÃ© parÃ¡metro debo cambiar primero?
**Respuesta rÃ¡pida**: `min_cluster_size` en `configuracion.py`

- Si tienes **muy pocos tÃ³picos** â†’ Reduce a 30
- Si tienes **demasiados tÃ³picos** â†’ Aumenta a 100

### Â¿Por quÃ© obtengo muchos tÃ³picos pequeÃ±os?
Esto significa que:
- `min_cluster_size` estÃ¡ muy bajo
- Los datos son muy diversos
- Hay mucho ruido en los textos

**SoluciÃ³n**: Aumenta `min_cluster_size` a 75 o 100.

### Â¿Por quÃ© obtengo muy pocos tÃ³picos?
Posibles causas:
- `min_cluster_size` estÃ¡ muy alto
- `topic_merge_delta` estÃ¡ muy alto (fusiona demasiado)
- Los datos son muy homogÃ©neos

**SoluciÃ³n**: Reduce `min_cluster_size` a 30 y `topic_merge_delta` a 0.05.

### Â¿QuÃ© hace exactamente `n_neighbors`?
Controla cuÃ¡ntos documentos cercanos considera para entender la estructura:
- **Valor alto** (100+): Ve el "panorama general", tÃ³picos amplios
- **Valor bajo** (30-): Se enfoca en detalles locales, tÃ³picos especÃ­ficos

**AnalogÃ­a**: Es como usar diferentes niveles de zoom en un mapa.

---

## ğŸ’¾ Preguntas sobre Datos

### Â¿Puedo usar mis propias noticias?
**SÃ­**, pero necesitarÃ­as:
1. Calcular los embeddings (proceso pesado, requiere GPU)
2. Tener el CSV en el mismo formato
3. Actualizar las rutas en `configuracion.py`

**RecomendaciÃ³n**: Empieza con los datos incluidos para aprender.

### Â¿QuÃ© columnas necesita el CSV?
MÃ­nimo requerido:
- `body`: El texto completo de la noticia
- `pub_date`: Fecha de publicaciÃ³n (para anÃ¡lisis temporal)
- `doc_id`: Identificador Ãºnico

### Â¿CuÃ¡ntas noticias necesito como mÃ­nimo?
- **MÃ­nimo absoluto**: 1,000 documentos
- **Recomendado**: 10,000+ documentos
- **Ã“ptimo**: 50,000+ documentos

Con menos de 1,000, los resultados no serÃ¡n confiables.

---

## ğŸ” Preguntas sobre Resultados

### Â¿CÃ³mo interpreto los scores de las palabras?
El score indica quÃ© tan representativa es una palabra del tÃ³pico:
- **0.8-1.0**: Palabra **muy** caracterÃ­stica del tÃ³pico
- **0.6-0.8**: Palabra **bastante** relevante
- **0.4-0.6**: Palabra **moderadamente** relacionada
- **< 0.4**: Palabra de contexto adicional

### Â¿Por quÃ© algunos tÃ³picos parecen similares?
Posibles razones:
- `topic_merge_delta` estÃ¡ muy bajo (no fusiona suficiente)
- Los temas realmente son diferentes pero relacionados
- Necesitas mÃ¡s datos para diferenciarlos mejor

**SoluciÃ³n**: Aumenta `topic_merge_delta` a 0.15 o 0.20.

### Â¿QuÃ© significa "documentos clasificados"?
Es la cantidad de documentos que fueron asignados a algÃºn tÃ³pico.
Algunos documentos pueden quedar sin clasificar si:
- Son muy diferentes a todo lo demÃ¡s (outliers)
- No cumplen con `min_cluster_size`

**Esto es normal**: tÃ­picamente 80-95% se clasifican.

---

## ğŸ› Preguntas sobre Errores

### Error: "No se encuentra el archivo noticias.csv"
**Causa**: No estÃ¡s en la carpeta correcta.

**SoluciÃ³n**:
```powershell
cd d:\Top2Vec\top2vec_para_economistas
uv run python ejecutar_modelo.py
```

### Error: "Memoria insuficiente" o "MemoryError"
**Causa**: Tu computador no tiene suficiente RAM.

**Soluciones** (en orden):
1. Cierra otros programas
2. Aumenta `min_cluster_size` a 100 en `configuracion.py`
3. Reduce `n_neighbors` a 30
4. Como Ãºltimo recurso, reduce el tamaÃ±o del dataset

### Error: "No module named 'top2vec'"
**Causa**: Las dependencias no estÃ¡n instaladas.

**SoluciÃ³n**:
```powershell
pip install -r requirements.txt
```

### El proceso toma demasiado tiempo (>2 horas)
**Posibles causas**:
- Computador lento
- Demasiados documentos
- ParÃ¡metros muy exigentes

**SoluciÃ³n**:
- Aumenta `min_cluster_size` (procesa mÃ¡s rÃ¡pido)
- Reduce `n_neighbors` a 30
- Verifica que no haya otros programas pesados corriendo

---

## ğŸ“Š Preguntas sobre AnÃ¡lisis

### Â¿CÃ³mo busco tÃ³picos sobre un tema especÃ­fico?
Usa el script `analisis_avanzado.py` (Ejemplo 1):
```python
keywords = ["inflaciÃ³n", "precios"]
topics = model.search_topics(keywords=keywords, num_topics=5)
```

### Â¿CÃ³mo veo las noticias reales de un tÃ³pico?
Usa el script `analisis_avanzado.py` (Ejemplo 2):
```python
documents = model.search_documents_by_topic(topic_num=0, num_docs=10)
```

### Â¿Puedo analizar la evoluciÃ³n temporal de tÃ³picos?
SÃ­, el script `analisis_avanzado.py` incluye un ejemplo (Ejemplo 5).
Crea grÃ¡ficos de frecuencia mensual de cada tÃ³pico.

### Â¿CÃ³mo exporto todo a Excel para anÃ¡lisis posterior?
El script principal ya genera `resumen_topicos.xlsx`.
Para anÃ¡lisis mÃ¡s detallado, ejecuta `analisis_avanzado.py` (Ejemplo 6).

---

## ğŸ“ Preguntas AcadÃ©micas

### Â¿Puedo citar este trabajo?
SÃ­, cita el paper original de Top2Vec:
```
Angelov, D. (2020). Top2Vec: Distributed Representations of Topics. 
arXiv preprint arXiv:2008.09470.
```

### Â¿Es reproducible el anÃ¡lisis?
SÃ­, gracias a:
- `random_state=42` en UMAP (fija la semilla aleatoria)
- Embeddings precalculados (siempre los mismos)
- ConfiguraciÃ³n documentada

Ejecutar con los mismos parÃ¡metros darÃ¡ los mismos resultados.

### Â¿QuÃ© tan robusto es el modelo?
Top2Vec es considerado **muy robusto** porque:
- No requiere especificar nÃºmero de tÃ³picos
- Usa algoritmos de clustering denso (HDBSCAN)
- Es menos sensible a ruido que LDA o NMF

---

## ğŸ”® Preguntas Avanzadas

### Â¿Puedo usar otros embeddings?
SÃ­, pero requiere modificar el cÃ³digo y recalcular todo.
Los embeddings actuales son de alta calidad (probablemente de un modelo transformer).

### Â¿Puedo integrar esto con otros anÃ¡lisis?
SÃ­, el script `analisis_avanzado.py` muestra cÃ³mo:
- Exportar documentos con tÃ³picos asignados
- Hacer anÃ¡lisis temporal
- Combinar con otros datasets

### Â¿Funciona para otros idiomas ademÃ¡s de espaÃ±ol?
SÃ­, Top2Vec funciona con cualquier idioma, pero:
- Los embeddings deben ser entrenados en ese idioma
- El tokenizer debe adaptarse (preservar caracteres especiales)

---

## ğŸ’¡ Consejos Finales

1. **Empieza simple**: Usa configuraciÃ³n por defecto primero
2. **Itera**: Ajusta parÃ¡metros segÃºn lo que observes
3. **Documenta**: Anota quÃ© configuraciÃ³n usaste para cada experimento
4. **Explora**: Usa `analisis_avanzado.py` para profundizar
5. **Pregunta**: Si algo no funciona, revisa los logs de error

---

**Â¿Tu pregunta no estÃ¡ aquÃ­?**
Revisa:
- ğŸ“– `README.md` - DocumentaciÃ³n completa
- ğŸš€ `INICIO_RAPIDO.md` - GuÃ­a rÃ¡pida
- ğŸ `analisis_avanzado.py` - Ejemplos de cÃ³digo
